{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1bf1e14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daa03757",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: User-defined SPARK_HOME (/opt/cloudera/parcels/CDH-6.2.0-1.cdh6.2.0.p0.967373/lib/spark) overrides detected (/opt/cloudera/parcels/CDH/lib/spark).\n",
      "WARNING: Running spark-class from user-defined location.\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/06 15:43:07 WARN lineage.LineageWriter: Lineage directory /var/log/spark/lineage doesn't exist or is not writable. Lineage for this application will be disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "import pyspark.sql.types as sqlt\n",
    "import pyspark.sql.functions as sqlf\n",
    "from pyspark import SparkConf\n",
    "try:\n",
    "    sc.stop()\n",
    "except:\n",
    "    pass\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "#HDFS_MASTER = 'hadoop-master'\n",
    "conf = SparkConf()\n",
    "conf.setMaster('local')\n",
    "conf.setAppName('spark-test')\n",
    "sc = SparkContext(conf=conf)\n",
    "sqlContext = SQLContext(sc)\n",
    "spark = sqlContext\n",
    "sql = spark.sql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5caba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "df.select(countDistinct(\"column_name\"))  # Возвращает количество уникальных значений в столбце \"column_name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197c5e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split\n",
    "df.select(split(\"column_name\", \",\"))  # Разделяет значение в столбце \"column_name\" по разделителю \",\" и возвращает массив с разбитыми значениями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509fa3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import dayofweek\n",
    "df.select(dayofweek(\"date_column\"))  # Возвращает номер дня недели (1-7) для значения в столбце \"date_column\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0235cdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat\n",
    "df.select(concat(\"column1\", \"column2\").alias(\"concat_column\"))  # Соединяет значения столбцов \"column1\" и \"column2\" в новый столбец \"concat_column\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1b9310",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import length, min\n",
    "df.select(min(length(\"column_name\")))  # Возвращает наименьшую длину строки в столбце \"column_name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63420279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "df.select(sum(\"column_name\"))  # Возвращает сумму значений в столбце \"column_name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e8629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "df.select(lit(\"new_value\").alias(\"column_name\"))  # Заменяет все значения столбца \"column_name\" на \"new_value\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2af8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import upper\n",
    "df.select(upper(\"column_name\"))  # Преобразует значения столбца \"column_name\" в верхний регистр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c672a273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count\n",
    "df.groupby(\"column_name\").agg(count(\"column_name\"))  # Группирует строки по значениям в столбце \"column_name\" и возвращает количество строк в каждой группе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadac2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.dropDuplicates([\"column1\", \"column2\"])  # Удаляет дубликаты строк, оставляя только уникальные значения в столбцах \"column1\" и \"column2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e62d402",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "df.select(to_date(\"column_name\"))  # Преобразует значение в столбце \"column_name\" в формат даты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d578778",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import floor\n",
    "df.select(floor(\"column_name\"))  # Отбрасывает десятичную часть чисел в столбце \"column_name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1655f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import substring\n",
    "df.select(substring(\"column_name\", 1, N))  # Возвращает первые N символов строки в столбце \"column_name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62687f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "df.filter(col(\"column_name\").isin([val1, val2, val3]))  # Отбирает строки, содержащие значения из столбца \"column_name\", которые присутствуют в списке [val1, val2, val3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301f35c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "df.select(regexp_replace(\"column_name\", \"[^\\w\\s]\", \"\"))  # Удаляет все символы пунктуации из значений в столбце \"column_name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b55671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.select(col(\"column_name\").cast(\"float\"))  # Преобразует значение в столбце \"column_name\" в число с плавающей запятой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32e61ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year\n",
    "df.select(year(\"date_column\"))  # Извлекает год из значения в столбце \"date_column\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b21800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.select(col(\"column_name\").cast(\"boolean\"))  # Преобразует значение в столбце \"column_name\" в логический тип данных (\"true\" или \"false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ddfc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, split\n",
    "df.select(explode(split(\"column_name\", \":\")))  # Преобразует одну строку с несколькими значениями в отдельные строки, разделяя их по разделителю \":\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880e4181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.filter(col(\"column_name\").contains(\"substring\"))  # Отбирает строки, содержащие подстроку \"substring\" в значении столбца \"column_name\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573cf619",
   "metadata": {},
   "source": [
    "### Для заданий 2-11 нужно написать два варианта решения, через Spark SQL и через PySpark API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026f2433",
   "metadata": {},
   "source": [
    "Задание 1. Загрузите файл в Spark DataFrame hdfs:///user/data_loader/new_folder/Salary_Data_Based_country_and_race.csv. \n",
    "Запишите таблицу в parquet hive table в свою схему, убедитесь, что заголовки корректны.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f8d57ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/06 15:43:18 WARN lineage.LineageWriter: Lineage directory /var/log/spark/lineage doesn't exist or is not writable. Lineage for this application will be disabled.\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('hdfs:///user/std03/Salary_Data_Based_country_and_race.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66f9821b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "Relation[_c0#10,Age#11,Gender#12,Education Level#13,Job Title#14,Years of Experience#15,Salary#16,Country#17,Race#18] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "_c0: string, Age: string, Gender: string, Education Level: string, Job Title: string, Years of Experience: string, Salary: string, Country: string, Race: string\n",
      "Relation[_c0#10,Age#11,Gender#12,Education Level#13,Job Title#14,Years of Experience#15,Salary#16,Country#17,Race#18] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Relation[_c0#10,Age#11,Gender#12,Education Level#13,Job Title#14,Years of Experience#15,Salary#16,Country#17,Race#18] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) FileScan csv [_c0#10,Age#11,Gender#12,Education Level#13,Job Title#14,Years of Experience#15,Salary#16,Country#17,Race#18] Batched: false, Format: CSV, Location: InMemoryFileIndex[hdfs://node01.tec.lan:8020/user/std03/Salary_Data_Based_country_and_race.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<_c0:string,Age:string,Gender:string,Education Level:string,Job Title:string,Years of Exper...\n"
     ]
    }
   ],
   "source": [
    "df.explain(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2693259f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, Age: string, Gender: string, Education Level: string, Job Title: string, Years of Experience: string, Salary: string, Country: string, Race: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f90bde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"Education Level\", \"Education_Level\").withColumnRenamed('Job Title', 'Job_Title').withColumnRenamed(\"Years of Experience\", \"Years_of_Experience\").withColumnRenamed('_c0', 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03ce153a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+---------------+---------------------+-------------------+--------+---------+----------------+\n",
      "|id |Age |Gender|Education_Level|Job_Title            |Years_of_Experience|Salary  |Country  |Race            |\n",
      "+---+----+------+---------------+---------------------+-------------------+--------+---------+----------------+\n",
      "|0  |32.0|Male  |Bachelor's     |Software Engineer    |5.0                |90000.0 |UK       |White           |\n",
      "|1  |28.0|Female|Master's       |Data Analyst         |3.0                |65000.0 |USA      |Hispanic        |\n",
      "|2  |45.0|Male  |PhD            |Senior Manager       |15.0               |150000.0|Canada   |White           |\n",
      "|3  |36.0|Female|Bachelor's     |Sales Associate      |7.0                |60000.0 |USA      |Hispanic        |\n",
      "|4  |52.0|Male  |Master's       |Director             |20.0               |200000.0|USA      |Asian           |\n",
      "|5  |29.0|Male  |Bachelor's     |Marketing Analyst    |2.0                |55000.0 |USA      |Hispanic        |\n",
      "|6  |42.0|Female|Master's       |Product Manager      |12.0               |120000.0|USA      |Asian           |\n",
      "|7  |31.0|Male  |Bachelor's     |Sales Manager        |4.0                |80000.0 |China    |Korean          |\n",
      "|8  |26.0|Female|Bachelor's     |Marketing Coordinator|1.0                |45000.0 |China    |Chinese         |\n",
      "|9  |38.0|Male  |PhD            |Senior Scientist     |10.0               |110000.0|Australia|Australian      |\n",
      "|10 |29.0|Male  |Master's       |Software Developer   |3.0                |75000.0 |UK       |Welsh           |\n",
      "|11 |48.0|Female|Bachelor's     |HR Manager           |18.0               |140000.0|UK       |Asian           |\n",
      "|12 |35.0|Male  |Bachelor's     |Financial Analyst    |6.0                |65000.0 |China    |Korean          |\n",
      "|13 |40.0|Female|Master's       |Project Manager      |14.0               |130000.0|USA      |African American|\n",
      "|14 |27.0|Male  |Bachelor's     |Customer Service Rep |2.0                |40000.0 |Canada   |Asian           |\n",
      "|15 |44.0|Male  |Bachelor's     |Operations Manager   |16.0               |125000.0|China    |Chinese         |\n",
      "|16 |33.0|Female|Master's       |Marketing Manager    |7.0                |90000.0 |USA      |Asian           |\n",
      "|17 |39.0|Male  |PhD            |Senior Engineer      |12.0               |115000.0|UK       |Mixed           |\n",
      "|18 |25.0|Female|Bachelor's     |Data Entry Clerk     |0.0                |35000.0 |UK       |Asian           |\n",
      "|19 |51.0|Male  |Bachelor's     |Sales Director       |22.0               |180000.0|Australia|Asian           |\n",
      "+---+----+------+---------------+---------------------+-------------------+--------+---------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/06 15:43:28 WARN csv.CSVDataSource: CSV header does not conform to the schema.\n",
      " Header: , Age, Gender, Education Level, Job Title, Years of Experience, Salary, Country, Race\n",
      " Schema: _c0, Age, Gender, Education Level, Job Title, Years of Experience, Salary, Country, Race\n",
      "Expected: _c0 but found: \n",
      "CSV file: hdfs://node01.tec.lan:8020/user/std03/Salary_Data_Based_country_and_race.csv\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4489426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(id,StringType,true),StructField(Age,StringType,true),StructField(Gender,StringType,true),StructField(Education_Level,StringType,true),StructField(Job_Title,StringType,true),StructField(Years_of_Experience,StringType,true),StructField(Salary,StringType,true),StructField(Country,StringType,true),StructField(Race,StringType,true)))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f293ff37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/06 15:43:32 WARN csv.CSVDataSource: CSV header does not conform to the schema.\n",
      " Header: , Age, Gender, Education Level, Job Title, Years of Experience, Salary, Country, Race\n",
      " Schema: _c0, Age, Gender, Education Level, Job Title, Years of Experience, Salary, Country, Race\n",
      "Expected: _c0 but found: \n",
      "CSV file: hdfs://node01.tec.lan:8020/user/std03/Salary_Data_Based_country_and_race.csv\n",
      "[Stage 2:>                                                          (0 + 1) / 1]SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.2.0-1.cdh6.2.0.p0.967373/jars/parquet-format-2.3.1-cdh6.2.0.jar!/shaded/parquet/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.2.0-1.cdh6.2.0.p0.967373/lib/spark/hive/hive-exec-2.1.1-cdh6.2.0.jar!/shaded/parquet/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [shaded.parquet.org.slf4j.helpers.NOPLoggerFactory]\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_p = df.write.format('parquet').mode('overwrite').saveAsTable('ivanov.salary_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c633bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: string, Age: string, Gender: string, Education_Level: string, Job_Title: string, Years_of_Experience: string, Salary: string, Country: string, Race: string]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.table('ivanov.salary_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00504875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(id,StringType,true),StructField(Age,StringType,true),StructField(Gender,StringType,true),StructField(Education_Level,StringType,true),StructField(Job_Title,StringType,true),StructField(Years_of_Experience,StringType,true),StructField(Salary,StringType,true),StructField(Country,StringType,true),StructField(Race,StringType,true)))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.table('ivanov.salary_p').schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23dbc49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+---------------+--------------------+-------------------+--------+---------+----------------+\n",
      "| id| Age|Gender|Education_Level|           Job_Title|Years_of_Experience|  Salary|  Country|            Race|\n",
      "+---+----+------+---------------+--------------------+-------------------+--------+---------+----------------+\n",
      "|  0|32.0|  Male|     Bachelor's|   Software Engineer|                5.0| 90000.0|       UK|           White|\n",
      "|  1|28.0|Female|       Master's|        Data Analyst|                3.0| 65000.0|      USA|        Hispanic|\n",
      "|  2|45.0|  Male|            PhD|      Senior Manager|               15.0|150000.0|   Canada|           White|\n",
      "|  3|36.0|Female|     Bachelor's|     Sales Associate|                7.0| 60000.0|      USA|        Hispanic|\n",
      "|  4|52.0|  Male|       Master's|            Director|               20.0|200000.0|      USA|           Asian|\n",
      "|  5|29.0|  Male|     Bachelor's|   Marketing Analyst|                2.0| 55000.0|      USA|        Hispanic|\n",
      "|  6|42.0|Female|       Master's|     Product Manager|               12.0|120000.0|      USA|           Asian|\n",
      "|  7|31.0|  Male|     Bachelor's|       Sales Manager|                4.0| 80000.0|    China|          Korean|\n",
      "|  8|26.0|Female|     Bachelor's|Marketing Coordin...|                1.0| 45000.0|    China|         Chinese|\n",
      "|  9|38.0|  Male|            PhD|    Senior Scientist|               10.0|110000.0|Australia|      Australian|\n",
      "| 10|29.0|  Male|       Master's|  Software Developer|                3.0| 75000.0|       UK|           Welsh|\n",
      "| 11|48.0|Female|     Bachelor's|          HR Manager|               18.0|140000.0|       UK|           Asian|\n",
      "| 12|35.0|  Male|     Bachelor's|   Financial Analyst|                6.0| 65000.0|    China|          Korean|\n",
      "| 13|40.0|Female|       Master's|     Project Manager|               14.0|130000.0|      USA|African American|\n",
      "| 14|27.0|  Male|     Bachelor's|Customer Service Rep|                2.0| 40000.0|   Canada|           Asian|\n",
      "| 15|44.0|  Male|     Bachelor's|  Operations Manager|               16.0|125000.0|    China|         Chinese|\n",
      "| 16|33.0|Female|       Master's|   Marketing Manager|                7.0| 90000.0|      USA|           Asian|\n",
      "| 17|39.0|  Male|            PhD|     Senior Engineer|               12.0|115000.0|       UK|           Mixed|\n",
      "| 18|25.0|Female|     Bachelor's|    Data Entry Clerk|                0.0| 35000.0|       UK|           Asian|\n",
      "| 19|51.0|  Male|     Bachelor's|      Sales Director|               22.0|180000.0|Australia|           Asian|\n",
      "+---+----+------+---------------+--------------------+-------------------+--------+---------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.table('ivanov.salary_p').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "440a0e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6704"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.table('ivanov.salary_p').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d40742b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/06 15:43:38 WARN csv.CSVDataSource: CSV header does not conform to the schema.\n",
      " Header: , Age, Gender, Education Level, Job Title, Years of Experience, Salary, Country, Race\n",
      " Schema: _c0, Age, Gender, Education Level, Job Title, Years of Experience, Salary, Country, Race\n",
      "Expected: _c0 but found: \n",
      "CSV file: hdfs://node01.tec.lan:8020/user/std03/Salary_Data_Based_country_and_race.csv\n"
     ]
    }
   ],
   "source": [
    "df_pa = df.write.mode(\"overwrite\").parquet(\"hdfs:///user/std03/salary_pa.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63b7dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_par = spark.read.parquet(\"hdfs:///user/std03/salary_pa.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2640eec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: string, Age: string, Gender: string, Education_Level: string, Job_Title: string, Years_of_Experience: string, Salary: string, Country: string, Race: string]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56569888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6704"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_par.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8544771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType\n",
    "employeesSchema = StructType([\n",
    "    StructField(\"id\", IntegerType()),\n",
    "    StructField(\"Age\", FloatType()),\n",
    "    StructField(\"Gender\", StringType()),\n",
    "    StructField(\"Education_Level\", StringType()),\n",
    "    StructField(\"Job_Title\", StringType()),\n",
    "    StructField(\"Years_of_Experience\", FloatType()),\n",
    "    StructField(\"Salary\", FloatType()),\n",
    "    StructField(\"Country\", StringType()),\n",
    "    StructField(\"Race\", StringType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d1084c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s = spark.read.csv('hdfs:///user/std03/Salary_Data_Based_country_and_race.csv', header = True, schema = employeesSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "944d639b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, Age: float, Gender: string, Education_Level: string, Job_Title: string, Years_of_Experience: float, Salary: float, Country: string, Race: string]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "279bfe7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(id,IntegerType,true),StructField(Age,FloatType,true),StructField(Gender,StringType,true),StructField(Education_Level,StringType,true),StructField(Job_Title,StringType,true),StructField(Years_of_Experience,FloatType,true),StructField(Salary,FloatType,true),StructField(Country,StringType,true),StructField(Race,StringType,true)))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a88cf44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/06 15:43:50 WARN csv.CSVDataSource: CSV header does not conform to the schema.\n",
      " Header: , Age, Gender, Education Level, Job Title, Years of Experience, Salary, Country, Race\n",
      " Schema: id, Age, Gender, Education_Level, Job_Title, Years_of_Experience, Salary, Country, Race\n",
      "Expected: id but found: \n",
      "CSV file: hdfs://node01.tec.lan:8020/user/std03/Salary_Data_Based_country_and_race.csv\n"
     ]
    }
   ],
   "source": [
    "df_p = df_s.write.format('parquet').mode('overwrite').saveAsTable('ivanov.salary_pa')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e53bdc5",
   "metadata": {},
   "source": [
    "Задание 2. Найдите средний возраст для каждого образовательного уровня в таблице."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04caa930",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+\n",
      "|Education_Level  |avgAge            |\n",
      "+-----------------+------------------+\n",
      "|High School      |26.854910714285715|\n",
      "|Master's Degree  |35.40241576605213 |\n",
      "|Bachelor's Degree|30.354653727393032|\n",
      "|null             |27.0              |\n",
      "|PhD              |41.16520467836257 |\n",
      "|phD              |27.0              |\n",
      "|Bachelor's       |29.978835978835978|\n",
      "|Master's         |33.895833333333336|\n",
      "+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.table('ivanov.salary_pa').groupBy(\"Education_Level\").agg(sqlf.avg(\"Age\").alias(\"avgAge\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7563d4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+\n",
      "|Education_Level  |avgAge            |\n",
      "+-----------------+------------------+\n",
      "|High School      |26.854910714285715|\n",
      "|Master's Degree  |35.40241576605213 |\n",
      "|Bachelor's Degree|30.354653727393032|\n",
      "|null             |27.0              |\n",
      "|PhD              |41.16520467836257 |\n",
      "|phD              |27.0              |\n",
      "|Bachelor's       |29.978835978835978|\n",
      "|Master's         |33.895833333333336|\n",
      "+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''select Education_Level, avg(Age) as avgAge\n",
    "                from ivanov.salary_pa\n",
    "                group by Education_Level''').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11977e53",
   "metadata": {},
   "source": [
    "Задание 3. Найдите образовательный уровень с наибольшим количеством работников."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2d01986",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 47:=============================>                        (110 + 1) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|  Education_Level|\n",
      "+-----------------+\n",
      "|Bachelor's Degree|\n",
      "+-----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(spark.table('ivanov.salary_pa')\n",
    ".groupBy(\"Education_Level\").count().orderBy(sqlf.col(\"count\").desc()).select(\"Education_Level\").show(1))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a9ab5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|Education_Level  |\n",
      "+-----------------+\n",
      "|Bachelor's Degree|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "            with t1 as\n",
    "            (select Education_Level, count(Education_Level) as count\n",
    "                from ivanov.salary_pa\n",
    "                group by Education_Level\n",
    "                \n",
    "            \n",
    "            )\n",
    "             select Education_Level from t1\n",
    "             where count = \n",
    "             (select max(count) from t1)\n",
    "            \n",
    "            ''').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33661503",
   "metadata": {},
   "source": [
    "Задание 4. Найдите средний доход для каждой страны и пола."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0614e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------------------+\n",
      "|Gender|Country  |avg_s             |\n",
      "+------+---------+------------------+\n",
      "|Female|UK       |108456.69293924466|\n",
      "|Female|China    |111291.21150592217|\n",
      "|Female|USA      |104992.6904376013 |\n",
      "|Female|Australia|107913.5651465798 |\n",
      "|Female|Canada   |106884.71134020618|\n",
      "|Male  |UK       |122175.69475138122|\n",
      "|Male  |USA      |119683.1204330176 |\n",
      "|Male  |China    |120226.3128342246 |\n",
      "|Male  |Australia|120896.76421636615|\n",
      "|Male  |Canada   |123982.06486486486|\n",
      "|Other |China    |112516.75         |\n",
      "|Other |Australia|104127.0          |\n",
      "|Other |UK       |129797.0          |\n",
      "|Other |Canada   |161347.0          |\n",
      "|Other |USA      |111517.33333333333|\n",
      "+------+---------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(spark.table('ivanov.salary_pa')\n",
    ".groupBy([\"Gender\", 'Country']).agg(sqlf.avg(\"salary\").alias(\"avg_s\"))\n",
    ".orderBy(sqlf.col(\"Gender\"))\n",
    ".filter(sqlf.col(\"Gender\").isNotNull())\n",
    ".show(truncate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "731879e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------------------+\n",
      "|Gender|Country  |avg               |\n",
      "+------+---------+------------------+\n",
      "|Female|UK       |108456.69293924466|\n",
      "|Female|China    |111291.21150592217|\n",
      "|Female|USA      |104992.6904376013 |\n",
      "|Female|Australia|107913.5651465798 |\n",
      "|Female|Canada   |106884.71134020618|\n",
      "|Male  |UK       |122175.69475138122|\n",
      "|Male  |USA      |119683.1204330176 |\n",
      "|Male  |China    |120226.3128342246 |\n",
      "|Male  |Australia|120896.76421636615|\n",
      "|Male  |Canada   |123982.06486486486|\n",
      "|Other |China    |112516.75         |\n",
      "|Other |Australia|104127.0          |\n",
      "|Other |UK       |129797.0          |\n",
      "|Other |Canada   |161347.0          |\n",
      "|Other |USA      |111517.33333333333|\n",
      "+------+---------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "            with t1 as\n",
    "            (select Gender, Country, avg(salary) as avg\n",
    "                from ivanov.salary_pa\n",
    "                group by Gender, Country\n",
    "                order by Gender\n",
    "            \n",
    "            )\n",
    "             select * from t1\n",
    "             where Gender is not null\n",
    "            \n",
    "            ''').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d36c42",
   "metadata": {},
   "source": [
    "Задание 5. Найдите медианный возраст для каждой расы в таблице."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a30ef7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+\n",
      "|            Race|median|\n",
      "+----------------+------+\n",
      "|         Chinese|  31.0|\n",
      "|African American|  32.0|\n",
      "|      Australian|  32.0|\n",
      "|           Mixed|  32.0|\n",
      "|          Korean|  32.0|\n",
      "|           White|  32.0|\n",
      "|        Hispanic|  31.0|\n",
      "|           Black|  32.0|\n",
      "|           Asian|  31.0|\n",
      "|           Welsh|  32.0|\n",
      "+----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.table('ivanov.salary_pa').groupBy('Race').agg(sqlf.expr('percentile(age, 0.5)').alias('median')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ca95803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe183e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def find_median(values_list):\n",
    "    try:\n",
    "        median = np.median(values_list) #get the median of values in a list in each row\n",
    "        return round(float(median), 2)\n",
    "    except Exception:\n",
    "        return None #if there is anything wrong with the given values\n",
    "\n",
    "median_finder = sqlf.udf(find_median,FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b0cf1693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 77:=======================================================>(74 + 1) / 75]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+\n",
      "|            Race|median|\n",
      "+----------------+------+\n",
      "|         Chinese|  31.0|\n",
      "|African American|  32.0|\n",
      "|      Australian|  32.0|\n",
      "|           Mixed|  32.0|\n",
      "|          Korean|  32.0|\n",
      "|           White|  32.0|\n",
      "|        Hispanic|  31.0|\n",
      "|           Black|  32.0|\n",
      "|           Asian|  31.0|\n",
      "|           Welsh|  32.0|\n",
      "+----------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "salaries_list = spark.table('ivanov.salary_pa').groupBy('Race').agg(sqlf.collect_list(\"age\").alias(\"age\"))\n",
    "salaries_list.withColumn(\"median\", median_finder(\"age\")).select(\"Race\", \"median\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d967f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+\n",
      "|Race            |median|\n",
      "+----------------+------+\n",
      "|Chinese         |31.0  |\n",
      "|African American|32.0  |\n",
      "|Australian      |32.0  |\n",
      "|Mixed           |32.0  |\n",
      "|Korean          |32.0  |\n",
      "|White           |32.0  |\n",
      "|Black           |32.0  |\n",
      "|Hispanic        |31.0  |\n",
      "|Asian           |31.0  |\n",
      "|Welsh           |32.0  |\n",
      "+----------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "           WITH tab AS \n",
    "                (\n",
    "                SELECT Race, age, COUNT(*) OVER (partition by Race) AS cnt,\n",
    "                    ROW_NUMBER() OVER (partition by race ORDER BY age) AS rn\n",
    "                FROM ivanov.salary_pa\n",
    "                )\n",
    "                SELECT Race, age as median\n",
    "                FROM tab\n",
    "                WHERE rn IN ((Cnt+1)/2, (Cnt+2)/2)         \n",
    "            \n",
    "            ''').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5764cda",
   "metadata": {},
   "source": [
    "Задание 6. Найдите общую суммарную зарплату для каждой работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "49d6fcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+-----------+\n",
      "|Job_Title                         |sum_salary |\n",
      "+----------------------------------+-----------+\n",
      "|Digital Marketing Manager         |4850000.0  |\n",
      "|Product Designer                  |4215000.0  |\n",
      "|Senior Sales Manager              |265000.0   |\n",
      "|Senior Software Architect         |120000.0   |\n",
      "|Financial Manager                 |1.917E7    |\n",
      "|Event Coordinator                 |105000.0   |\n",
      "|Financial Analyst                 |3420000.0  |\n",
      "|Senior Product Marketing Manager  |8735000.0  |\n",
      "|Business Intelligence Analyst     |85000.0    |\n",
      "|Junior Software Engineer          |2569000.0  |\n",
      "|Senior IT Consultant              |220000.0   |\n",
      "|Sales Executive                   |1635000.0  |\n",
      "|Senior Researcher                 |150000.0   |\n",
      "|Senior Project Engineer           |5.2859472E7|\n",
      "|Network Engineer                  |60000.0    |\n",
      "|Sales Associate                   |2510000.0  |\n",
      "|Public Relations Manager          |90000.0    |\n",
      "|Junior Business Analyst           |400000.0   |\n",
      "|Digital Marketing Specialist      |950000.0   |\n",
      "|Junior Customer Support Specialist|35000.0    |\n",
      "+----------------------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.table('ivanov.salary_pa').groupBy(\"Job_Title\").agg(sqlf.sum(\"salary\").alias(\"sum_salary\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e948307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+-----------+\n",
      "|Job_Title                         |sum_salary |\n",
      "+----------------------------------+-----------+\n",
      "|Digital Marketing Manager         |4850000.0  |\n",
      "|Product Designer                  |4215000.0  |\n",
      "|Senior Sales Manager              |265000.0   |\n",
      "|Senior Software Architect         |120000.0   |\n",
      "|Financial Manager                 |1.917E7    |\n",
      "|Event Coordinator                 |105000.0   |\n",
      "|Financial Analyst                 |3420000.0  |\n",
      "|Senior Product Marketing Manager  |8735000.0  |\n",
      "|Business Intelligence Analyst     |85000.0    |\n",
      "|Junior Software Engineer          |2569000.0  |\n",
      "|Senior IT Consultant              |220000.0   |\n",
      "|Sales Executive                   |1635000.0  |\n",
      "|Senior Researcher                 |150000.0   |\n",
      "|Senior Project Engineer           |5.2859472E7|\n",
      "|Network Engineer                  |60000.0    |\n",
      "|Sales Associate                   |2510000.0  |\n",
      "|Public Relations Manager          |90000.0    |\n",
      "|Junior Business Analyst           |400000.0   |\n",
      "|Digital Marketing Specialist      |950000.0   |\n",
      "|Junior Customer Support Specialist|35000.0    |\n",
      "+----------------------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "               SELECT Job_Title, sum(salary)  AS sum_salary\n",
    "               FROM ivanov.salary_pa\n",
    "               group by Job_Title\n",
    "                  \n",
    "            ''').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c37e29d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+-----------+\n",
      "|Job_Title                         |sum_salary |\n",
      "+----------------------------------+-----------+\n",
      "|Digital Marketing Manager         |4850000.0  |\n",
      "|Product Designer                  |4215000.0  |\n",
      "|Senior Sales Manager              |265000.0   |\n",
      "|Senior Software Architect         |120000.0   |\n",
      "|Event Coordinator                 |105000.0   |\n",
      "|Financial Manager                 |1.917E7    |\n",
      "|Financial Analyst                 |3420000.0  |\n",
      "|Senior Product Marketing Manager  |8735000.0  |\n",
      "|Business Intelligence Analyst     |85000.0    |\n",
      "|Junior Software Engineer          |2569000.0  |\n",
      "|Senior IT Consultant              |220000.0   |\n",
      "|Sales Executive                   |1635000.0  |\n",
      "|Senior Project Engineer           |5.2859472E7|\n",
      "|Senior Researcher                 |150000.0   |\n",
      "|Network Engineer                  |60000.0    |\n",
      "|Public Relations Manager          |90000.0    |\n",
      "|Sales Associate                   |2510000.0  |\n",
      "|Digital Marketing Specialist      |950000.0   |\n",
      "|Junior Business Analyst           |400000.0   |\n",
      "|Junior Customer Support Specialist|35000.0    |\n",
      "+----------------------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "               SELECT distinct(Job_Title), sum(salary) OVER (partition by Job_Title) AS sum_salary\n",
    "               FROM ivanov.salary_pa\n",
    "                  \n",
    "            ''').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4147a847",
   "metadata": {},
   "source": [
    "Задание 7. Найдите страну с самой высокой средней зарплатой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e6d26812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 113:====================================================>(198 + 1) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|Country|avg_salary        |\n",
      "+-------+------------------+\n",
      "|Canada |116556.73283018867|\n",
      "+-------+------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.table('ivanov.salary_pa').groupBy(\"Country\").agg(sqlf.mean(\"salary\").alias(\"avg_salary\")).sort(\"avg_salary\", ascending=False).show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "893fb0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 115:========================================>            (153 + 4) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|Country|avg_salary        |\n",
      "+-------+------------------+\n",
      "|Canada |116556.73283018867|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "               SELECT Country, avg(salary)  AS avg_salary\n",
    "               FROM ivanov.salary_pa\n",
    "               group by Country\n",
    "               order by avg_salary desc\n",
    "               limit 1\n",
    "                  \n",
    "            ''').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5f657aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6796a96f",
   "metadata": {},
   "source": [
    "Задание 8. Найдите наиболее распространенный образовательный уровень среди мужчин и женщин."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cef80bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b12dc6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+\n",
      "|gender|Education_Level  |\n",
      "+------+-----------------+\n",
      "|Female|Bachelor's Degree|\n",
      "|Male  |Bachelor's Degree|\n",
      "+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(spark.table('ivanov.salary_pa').groupBy([\"gender\", \"Education_Level\"]).count()\n",
    ".withColumn('rn', sqlf.row_number().over(Window.partitionBy(\"gender\").orderBy(sqlf.desc('count'))))\n",
    ".filter(\"rn = 1\")\n",
    ".filter(sqlf.col(\"gender\").isin(['Female', 'Male']))\n",
    ".drop('count', 'rn')\n",
    ".show(truncate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da109b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 135:=======================================>             (149 + 1) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+\n",
      "|gender|Education_Level  |\n",
      "+------+-----------------+\n",
      "|Female|Bachelor's Degree|\n",
      "|Male  |Bachelor's Degree|\n",
      "+------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "            with t1 as (\n",
    "               SELECT gender, Education_Level, count(Education_Level)  AS cnt\n",
    "               FROM ivanov.salary_pa\n",
    "               group by gender, Education_Level\n",
    "               order by gender),\n",
    "             t2  (select *,\n",
    "             ROW_NUMBER() OVER (partition by gender ORDER BY cnt desc) AS rn\n",
    "             from t1)\n",
    "             \n",
    "             select gender, Education_Level from t2\n",
    "             where rn = 1 and gender in ('Female', 'Male' )\n",
    "            \n",
    "             \n",
    "             \n",
    "            ''').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d53fae",
   "metadata": {},
   "source": [
    "Задание 9. Найдите средний доход для каждой группы возраста (18-25, 26-35, 36-50, 51+)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00dcc05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, Age: float, Gender: string, Education_Level: string, Job_Title: string, Years_of_Experience: float, Salary: float, Country: string, Race: string]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.table('ivanov.salary_pa')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "64f734ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+\n",
      "|gr_age|       avg_salary|\n",
      "+------+-----------------+\n",
      "|     1|93236.54019933555|\n",
      "|     3|191834.7513227513|\n",
      "|     2| 158072.977443609|\n",
      "+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df\n",
    ".withColumn(\"gr_age\", sqlf.when(df.Age < 18.0, 0).when(df.Age <= 35.0, 1).when(df.Age <= 50.0, 2).when(df.Age > 50.0, 3))\n",
    ".groupBy(\"gr_age\").agg(sqlf.mean(\"salary\").alias(\"avg_salary\"))\n",
    ".filter(sqlf.col(\"gr_age\").isNotNull())\n",
    ".show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "408a82a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+\n",
      "|gr_age|avg_salary       |\n",
      "+------+-----------------+\n",
      "|1     |93236.54019933555|\n",
      "|3     |191834.7513227513|\n",
      "|2     |158072.977443609 |\n",
      "+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "            with t1 as (\n",
    "               SELECT gender, salary, age,\n",
    "               case \n",
    "                    when age < 18.0 then 0\n",
    "                    when age <=35.0 then 1\n",
    "                    when age <=50.0 then 2\n",
    "                    when age > 50.0 then 3\n",
    "                    \n",
    "              end gr_age\n",
    "               FROM ivanov.salary_pa\n",
    "               )\n",
    "            \n",
    "             \n",
    "             select gr_age, avg(salary) as avg_salary from t1\n",
    "             where gr_age is not null\n",
    "             group by gr_age\n",
    "             \n",
    "             \n",
    "            ''').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef118f2",
   "metadata": {},
   "source": [
    "Задание 10. Найдите страны, где количество работников каждой расы превышает среднее количество работников по всем расам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4d623230",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/06 15:49:56 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "[Stage 163:============================================>        (167 + 2) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|Country  |\n",
      "+---------+\n",
      "|Australia|\n",
      "|Canada   |\n",
      "|China    |\n",
      "+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(df\n",
    ".groupBy(['Country', 'race']).count().orderBy('Country')\n",
    ".withColumn('avg', sqlf.mean('count').over(Window().partitionBy()))\n",
    ".filter(sqlf.col(\"count\") > sqlf.col(\"avg\"))\n",
    ".drop('count', 'race', 'avg')\n",
    ".select('Country').distinct()\n",
    ".show(truncate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cf5141fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 175:=========================================>           (155 + 1) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|Country  |\n",
      "+---------+\n",
      "|Australia|\n",
      "|Canada   |\n",
      "|China    |\n",
      "+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "            with t1 as (\n",
    "               SELECT Country, race, count(race) as cnt\n",
    "               FROM ivanov.salary_pa\n",
    "               group by Country, race\n",
    "               order by Country\n",
    "               )\n",
    "             \n",
    "             select distinct Country from t1\n",
    "             where cnt > (select avg(cnt) from t1)\n",
    "            \n",
    "             \n",
    "            ''').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9fcffa",
   "metadata": {},
   "source": [
    "Задание 11. Найдите топ-3 работы с самой высокой средней зарплатой среди людей с опытом работы от 10 лет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "02f1a74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+--------+\n",
      "|Job_Title               |avg_s   |\n",
      "+------------------------+--------+\n",
      "|CEO                     |250000.0|\n",
      "|Chief Technology Officer|250000.0|\n",
      "|Chief Data Officer      |220000.0|\n",
      "+------------------------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(df\n",
    ".withColumn(\"exp_10\", sqlf.when(df.Years_of_Experience >= 10.0, 10))\n",
    ".filter(sqlf.col(\"exp_10\") == 10)\n",
    ".groupBy(\"Job_Title\").agg(sqlf.mean(\"salary\").alias(\"avg_s\"))\n",
    ".orderBy(sqlf.desc('avg_s'))\n",
    ".show(3, truncate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6c44ee6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 183:===================================================> (195 + 1) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+--------+\n",
      "|Job_Title               |avg_s   |\n",
      "+------------------------+--------+\n",
      "|CEO                     |250000.0|\n",
      "|Chief Technology Officer|250000.0|\n",
      "|Chief Data Officer      |220000.0|\n",
      "+------------------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "            with t1 as (\n",
    "               SELECT Job_Title, salary, Years_of_Experience,\n",
    "               case \n",
    "                    when Years_of_Experience >= 10.0 then 10\n",
    "                                        \n",
    "              end y\n",
    "               FROM ivanov.salary_pa\n",
    "               ), t2 as (\n",
    "               select * from t1\n",
    "               where y = 10\n",
    "               ), t3 as (\n",
    "               select Job_Title, avg(salary) avg_s from t2\n",
    "               group by Job_Title\n",
    "               order by avg_s desc\n",
    "               limit 3\n",
    "               )\n",
    "               \n",
    "            \n",
    "             \n",
    "             select * from t3\n",
    "             \n",
    "             \n",
    "             \n",
    "            ''').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000e0c91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
